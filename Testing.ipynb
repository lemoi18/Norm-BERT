{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3cba61a-3371-468a-ba0d-fa71de92801b",
   "metadata": {},
   "source": [
    "# Test Env For Testing the G2P Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eeb7443a-8549-4adf-a824-c82c44686aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lemoi18/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "#### Normalizeding\n",
    "import sys\n",
    "sys.path.append('/home/lemoi18/NB-PL-BERT/NbConverters')  # Add the path to your NBtext_normalize.py\n",
    "from NBtext_normalize import normalize_text\n",
    "###### noot used for now\n",
    "\n",
    "import phonetisaurus\n",
    "import logging\n",
    "from convert_pa import nofabet_to_ipa, nofabet_to_sampa, sampa_to_ipa\n",
    "\n",
    "import re\n",
    "\n",
    "def apply_custom_adjustments(text):\n",
    "    # List of century indicators\n",
    "    centuries = ['atten', 'nitten', 'tjue', 'tjueen', 'tjueto','tjuetre','tjuefire']\n",
    "    \n",
    "    # List of decade words\n",
    "    decades = ['ti', 'tjue', 'tretti', 'førti', 'femti', 'seksti', 'sytti', 'åtti', 'nitti', 'hundre']\n",
    "    \n",
    "    # Create regex patterns\n",
    "    century_pattern = r'|'.join(centuries)\n",
    "    decade_pattern = r'|'.join(decades)\n",
    "    \n",
    "    # Pattern to match phrases like 'nitten nitti - årene'\n",
    "    decade_phrase_pattern = rf'\\b({century_pattern})\\b \\b({decade_pattern})\\b - årene'\n",
    "    \n",
    "    # Replacement pattern to convert to 'nitten nitti-tallet'\n",
    "    replacement_pattern = r'\\1 \\2-tallet'\n",
    "\n",
    "    custom_replacements = {\n",
    "        r'e - post': 'e-post',  # Correcting 'e - post' back to 'e-post'\n",
    "        r'e - posten': 'e-posten',\n",
    "        r'«\\s+': '«',  # Remove spaces after '«'\n",
    "        r'\\s+»': '»',  # Remove spaces before '»'\n",
    "        decade_phrase_pattern: replacement_pattern,  # Correcting 'nitten nitti - årene' to 'nitten nitti-tallet'\n",
    "        r'\\s+-\\s+': '-',  # Remove spaces around hyphens\n",
    "    }\n",
    "\n",
    "    # Apply each custom replacement\n",
    "    for pattern, replacement in custom_replacements.items():\n",
    "        text = re.sub(pattern, replacement, text)\n",
    "\n",
    "    # Remove spaces around punctuation (.,!?;) but keep a space after commas\n",
    "    text = re.sub(r'\\s*([.!?;])\\s*', r'\\1', text)\n",
    "    \n",
    "    # Ensure a space after commas if not present\n",
    "    text = re.sub(r',\\s*', ', ', text)\n",
    "\n",
    "    # Remove comma if it's the last character\n",
    "    text = re.sub(r',\\s*$', '', text)\n",
    "\n",
    "    # Handle unmatched quotation marks\n",
    "    num_left_quotes = text.count('«')\n",
    "    num_right_quotes = text.count('»')\n",
    "\n",
    "    if num_left_quotes != num_right_quotes:\n",
    "        if num_left_quotes > num_right_quotes:\n",
    "            text = remove_unmatched_quotes(text, '«')\n",
    "        elif num_right_quotes > num_left_quotes:\n",
    "            text = remove_unmatched_quotes(text, '»')\n",
    "    \n",
    "    return text\n",
    "\n",
    "def remove_unmatched_quotes(text, quote_char):\n",
    "    \"\"\"Remove unmatched quotation marks from the text.\"\"\"\n",
    "    if quote_char == '«':\n",
    "        if text.count('«') > text.count('»'):\n",
    "            text = re.sub(r'«([^»]*)$', r'\\1', text)  # Remove the last unmatched '«'\n",
    "    elif quote_char == '»':\n",
    "        if text.count('»') > text.count('«'):\n",
    "            text = re.sub(r'^([^«]*)»', r'\\1', text)  # Remove the first unmatched '»'\n",
    "    return text\n",
    "\n",
    "# Function to normalize text using custom rules\n",
    "def normalize_text_with_custom_rules(text):\n",
    "    normalized_text = normalize_text(text)  # Perform initial normalization\n",
    "    normalized_text = apply_custom_adjustments(normalized_text)  # Apply custom adjustments\n",
    "    return normalized_text\n",
    "\n",
    "\n",
    "\n",
    "###### Written\n",
    "###### Spoken \n",
    "def transcribe_words(words, dialect='e', style=\"written\"):\n",
    "    transcriptions = phonetisaurus.predict(words, model_path=\"/home/lemoi18/G2P-no/models/nb_e_spoken.fst\")\n",
    "    return transcriptions\n",
    "\n",
    "def format_transcription(pronunciation):\n",
    "    return \" \".join(pronunciation)\n",
    "\n",
    "def transcribe(text, dialect='e', style=\"spoken\"):\n",
    "    words = text.split()\n",
    "    transcriptions = transcribe_words(words, dialect=dialect, style=style)\n",
    "    return [(word, format_transcription(pron)) for word, pron in transcriptions]\n",
    "    \n",
    "def phonimize_IPA(text):\n",
    "    tokens = re.findall(r\"[\\w']+|[.,!?;:]\", text)\n",
    "    transcriptions = transcribe(' '.join([t for t in tokens if re.match(r\"[\\w']+\", t)]))\n",
    "\n",
    "    transcription = []\n",
    "    result_index = 0\n",
    "\n",
    "    for token in tokens:\n",
    "        if re.match(r\"[.,!?;:]\", token):  # Punctuation check\n",
    "            if transcription:\n",
    "                transcription[-1] += token\n",
    "        else:  # It's a word\n",
    "            word, phonetic = transcriptions[result_index]\n",
    "            # Convert phonetic transcription to IPA\n",
    "            ipa_transcription = nofabet_to_ipa(phonetic)\n",
    "            # Remove syllable breaks (.)\n",
    "            ipa_transcription = ipa_transcription.replace('.', '')\n",
    "            transcription.extend(ipa_transcription.split())\n",
    "            result_index += 1\n",
    "\n",
    "    ps = ' '.join(transcription)\n",
    "    return ps\n",
    "\n",
    "\n",
    "def phonimize_NOFAB(text):\n",
    "    \n",
    "\n",
    "    tokens = re.findall(r\"[\\w']+|[.,!?;:]\", text)\n",
    "    transcriptions = transcribe(' '.join([t for t in tokens if re.match(r\"[\\w']+\", t)]))\n",
    "        \n",
    "    transcription = []\n",
    "    result_index = 0\n",
    "        \n",
    "    for token in tokens:\n",
    "        if re.match(r\"[.,!?;:]\", token):\n",
    "            transcription += token\n",
    "        else:  # It's a word\n",
    "            if result_index < len(transcriptions):\n",
    "                word, phonetic = transcriptions[result_index]\n",
    "                transcription.extend(phonetic.split())\n",
    "                result_index += 1\n",
    "            else:\n",
    "                print(f\"Warning: result_index {result_index} is out of range for transcriptions.\")\n",
    "                break  # or handle the error accordingly\n",
    "        \n",
    "    ps = transcription\n",
    "    ps = ' '.join(transcription)\n",
    "    return ps\n",
    "\n",
    "def get_word_window(text, index, window_size=5):\n",
    "    \"\"\"Get a window of words around the specified index in the text.\"\"\"\n",
    "    words = text.split()\n",
    "    start = max(0, index - window_size)\n",
    "    end = min(len(words), index + window_size + 1)\n",
    "    return ' '.join(words[start:end])\n",
    "\n",
    "\n",
    "def process_train_listNormalize(input_file_path, output_file_path, k=100):\n",
    "    with open(input_file_path, 'r', encoding='utf-8') as infile, open(output_file_path, 'w', encoding='utf-8') as outfile:\n",
    "        for i, line in enumerate(infile):\n",
    "            # Split the line into audio_path, text, and speaker_nr\n",
    "            columns = line.split('|')\n",
    "\n",
    "            # Normalize the second column (text)\n",
    "            original_text = columns[1].strip()\n",
    "            \n",
    "            phonimize_text = normalize_text_with_custom_rules(original_text)\n",
    "\n",
    "            # Reconstruct the line with the normalized text\n",
    "            columns[1] = phonimize_text\n",
    "\n",
    "            # Write the modified line to the output file in the same format\n",
    "            outfile.write('|'.join(columns))\n",
    "\n",
    "            # Stop after processing `k` lines (if required)\n",
    "            if (i + 1) >= k:\n",
    "                break\n",
    "\n",
    "\n",
    "\n",
    "def process_train_listPhonminze(input_file_path, output_file_path):\n",
    "    with open(input_file_path, 'r', encoding='utf-8') as infile, open(output_file_path, 'w', encoding='utf-8') as outfile:\n",
    "        lines = infile.readlines()\n",
    "\n",
    "        for line in lines:\n",
    "            # Split the line into audio_path, text, and speaker_nr\n",
    "            columns = line.split('|')\n",
    "\n",
    "            # Normalize the second column (text)\n",
    "            original_text = columns[1].strip()\n",
    "            \n",
    "            phonimize_text = phonimize_NOFAB(original_text)\n",
    "\n",
    "            # Reconstruct the line with the normalized text\n",
    "            columns[1] = phonimize_text\n",
    "\n",
    "            # Write the modified line to the output file in the same format\n",
    "            outfile.write('|'.join(columns))\n",
    "\n",
    "            \n",
    "\n",
    "# Example usage:\n",
    "#process_train_listPhonminze('normalized.txt', 'phonimized.txt')\n",
    "#process_train_listNormalize('outputbooks.txt' , 'normalized.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8307f017-4ece-4b7e-bd16-8e3bb4f68131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import difflib\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "import pandas as pd\n",
    "import difflib\n",
    "\n",
    "def get_word_window(tokens, index, window_size=5):\n",
    "    \"\"\"Get a window of words around the specified index in the token list.\"\"\"\n",
    "    start = max(0, index - window_size)\n",
    "    end = min(len(tokens), index + window_size + 1)\n",
    "    return ' '.join(tokens[start:end])\n",
    "\n",
    "def find_real_changes(original_tokens, normalized_tokens):\n",
    "    \"\"\"Find the real changes between two token lists, ignoring shifts in position.\"\"\"\n",
    "    diff = list(difflib.ndiff(original_tokens, normalized_tokens))\n",
    "    changes = []\n",
    "    \n",
    "    orig_index = 0  # Index for original tokens\n",
    "    norm_index = 0  # Index for normalized tokens\n",
    "    \n",
    "    for d in diff:\n",
    "        if d.startswith('- ') and orig_index < len(original_tokens):  # Word removed from original\n",
    "            changes.append((orig_index, original_tokens[orig_index], 'removed'))\n",
    "            orig_index += 1\n",
    "        elif d.startswith('+ ') and norm_index < len(normalized_tokens):  # Word added in normalized\n",
    "            changes.append((norm_index, normalized_tokens[norm_index], 'added'))\n",
    "            norm_index += 1\n",
    "        elif d.startswith('  '):  # No change, increment both indices\n",
    "            if orig_index < len(original_tokens):\n",
    "                orig_index += 1\n",
    "            if norm_index < len(normalized_tokens):\n",
    "                norm_index += 1\n",
    "    \n",
    "    return changes\n",
    "\n",
    "def process_train_listNormalize_with_context(input_file_path, output_file_path, k=100):\n",
    "    original_texts = []\n",
    "    normalized_texts = []\n",
    "    contexts = []\n",
    "\n",
    "    with open(input_file_path, 'r', encoding='utf-8') as infile, open(output_file_path, 'w', encoding='utf-8') as outfile:\n",
    "        for i, line in enumerate(infile):\n",
    "            # Split the line into audio_path, text, and speaker_nr\n",
    "            columns = line.split('|')\n",
    "\n",
    "            # Normalize the second column (text)\n",
    "            original_text = columns[1].strip()\n",
    "            phonimize_text = normalize_text_with_custom_rules(original_text)\n",
    "\n",
    "            # Tokenize both original and normalized texts\n",
    "            original_tokens = original_text.split()\n",
    "            normalized_tokens = phonimize_text.split()\n",
    "\n",
    "            # Find real changes using diff logic\n",
    "            changes = find_real_changes(original_tokens, normalized_tokens)\n",
    "\n",
    "            # Collect the context around each change\n",
    "            for index, changed_word, change_type in changes:\n",
    "                # Get 5-word context around the changed word in both original and normalized text\n",
    "                original_context = get_word_window(original_tokens, index)\n",
    "                normalized_context = get_word_window(normalized_tokens, index)\n",
    "\n",
    "                # Collect the data for the markdown table\n",
    "                original_texts.append(original_context)\n",
    "                normalized_texts.append(normalized_context)\n",
    "                contexts.append(f\"Change at word {index+1}: '{changed_word}' ({change_type})\")\n",
    "\n",
    "            # Write the modified line to the output file in the same format\n",
    "            columns[1] = phonimize_text\n",
    "            outfile.write('|'.join(columns))\n",
    "\n",
    "            # Stop after processing `k` lines (if required)\n",
    "            if (i + 1) >= k:\n",
    "                break\n",
    "\n",
    "    # Create a DataFrame for comparison\n",
    "    df = pd.DataFrame({\n",
    "        \"Original Text (Context)\": original_texts,\n",
    "        \"Normalized Text (Context)\": normalized_texts,\n",
    "        \"Change Description\": contexts\n",
    "    })\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Call the function and create the comparison DataFrame\n",
    "df = process_train_listNormalize_with_context('outputbooks.txt' , 'normalized.txt', k=5000)\n",
    "\n",
    "# Convert DataFrame to markdown format\n",
    "markdown_table = df.to_markdown(index=True)\n",
    "display(Markdown(markdown_table))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10b55486-9f7d-4b10-8725-cb3e89f1e7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at NbAiLab/nb-bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: Lars, Label: LABEL_0\n",
      "Entity: -, Label: LABEL_1\n",
      "Entity: Erik, Label: LABEL_0\n",
      "Entity: Moi, Label: LABEL_0\n",
      "Entity: har, Label: LABEL_1\n",
      "Entity: et, Label: LABEL_1\n",
      "Entity: møte, Label: LABEL_1\n",
      "Entity: den, Label: LABEL_1\n",
      "Entity: 23, Label: LABEL_0\n",
      "Entity: ., Label: LABEL_1\n",
      "Entity: juni, Label: LABEL_1\n",
      "Entity: 2023, Label: LABEL_0\n",
      "Entity: i, Label: LABEL_1\n",
      "Entity: Oslo, Label: LABEL_1\n",
      "Entity: ., Label: LABEL_1\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load a Norwegian BERT model\n",
    "model_name = \"NbAiLab/nb-bert-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "\n",
    "# Reconstruct words by merging sub-word tokens\n",
    "def reconstruct_words(tokens):\n",
    "    words = []\n",
    "    current_word = \"\"\n",
    "    for token in tokens:\n",
    "        if token.startswith(\"##\"):  # Handling sub-word tokens\n",
    "            current_word += token[2:]\n",
    "        else:\n",
    "            if current_word:\n",
    "                words.append(current_word)\n",
    "            current_word = token\n",
    "    if current_word:\n",
    "        words.append(current_word)\n",
    "    return words\n",
    "\n",
    "# Define a pipeline for NER\n",
    "ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Input text containing a date\n",
    "text = \"Lars-Erik Moi har et møte den 23. juni 2023 i Oslo.\"\n",
    "\n",
    "# Get NER results\n",
    "ner_results = ner_pipeline(text)\n",
    "\n",
    "# Extract tokens and labels\n",
    "tokens = [entity['word'] for entity in ner_results]\n",
    "labels = [entity['entity'] for entity in ner_results]\n",
    "\n",
    "# Reconstruct full words from subword tokens\n",
    "reconstructed_tokens = reconstruct_words(tokens)\n",
    "\n",
    "# Print reconstructed words along with their labels\n",
    "for i, word in enumerate(reconstructed_tokens):\n",
    "    print(f\"Entity: {word}, Label: {labels[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0142019b-10a1-41c2-9cfc-cb19acf977cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import asyncio\n",
    "import aiofiles\n",
    "import nest_asyncio\n",
    "\n",
    "sys.path.append('/home/lemoi18/NB-PL-BERT/NbConverters')  # Add the path to your NBtext_normalize.py\n",
    "from NBtext_normalize import normalize_text\n",
    "\n",
    "import phonetisaurus\n",
    "from convert_pa import nofabet_to_ipa, nofabet_to_sampa, sampa_to_ipa\n",
    "\n",
    "nest_asyncio.apply()  # To allow asyncio.run() to be called from a running event loop\n",
    "\n",
    "async def transcribe_words_async(words, dialect='e', style=\"written\"):\n",
    "    loop = asyncio.get_event_loop()\n",
    "    transcriptions = await loop.run_in_executor(None, phonetisaurus.predict, words, \"/home/lemoi18/G2P-no/models/nb_e_written.fst\")\n",
    "    return transcriptions\n",
    "\n",
    "def format_transcription(pronunciation):\n",
    "    return \"\".join(pronunciation)\n",
    "\n",
    "async def transcribe_async(text, dialect='e', style=\"written\"):\n",
    "    words = text.split()\n",
    "    transcriptions = await transcribe_words_async(words, dialect=dialect, style=style)\n",
    "    return [(word, format_transcription(pron)) for word, pron in transcriptions]\n",
    "\n",
    "async def phonimize_NOFAB_async(text):\n",
    "    tokens = re.findall(r\"[\\w']+|[.,!?;:]\", text)\n",
    "    transcriptions = await transcribe_async(' '.join([t for t in tokens if re.match(r\"[\\w']+\", t)]))\n",
    "        \n",
    "    transcription = []\n",
    "    result_index = 0\n",
    "        \n",
    "    for token in tokens:\n",
    "        if re.match(r\"[.,!?;:]\", token):\n",
    "            transcription.append(token)\n",
    "        else:  # It's a word\n",
    "            if result_index < len(transcriptions):\n",
    "                word, phonetic = transcriptions[result_index]\n",
    "                transcription.extend(phonetic.split())\n",
    "                result_index += 1\n",
    "            else:\n",
    "                print(f\"Warning: result_index {result_index} is out of range for transcriptions.\")\n",
    "                break  # or handle the error accordingly\n",
    "        \n",
    "    ps = ' '.join(transcription)\n",
    "    return ps\n",
    "\n",
    "async def process_train_listPhonminze_async(input_file_path, output_file_path):\n",
    "    async with aiofiles.open(input_file_path, 'r', encoding='utf-8') as infile, \\\n",
    "               aiofiles.open(output_file_path, 'w', encoding='utf-8') as outfile:\n",
    "        lines = await infile.readlines()\n",
    "\n",
    "        for line in lines:\n",
    "            # Split the line into audio_path, text, and speaker_nr\n",
    "            columns = line.split('|')\n",
    "\n",
    "            # Normalize the second column (text)\n",
    "            original_text = columns[1].strip()\n",
    "            \n",
    "            phonimize_text = await phonimize_NOFAB_async(original_text)\n",
    "\n",
    "            # Reconstruct the line with the normalized text\n",
    "            columns[1] = phonimize_text\n",
    "\n",
    "            # Write the modified line to the output file in the same format\n",
    "            await outfile.write('|'.join(columns))\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(process_train_listPhonminze_async('normalized.txt', 'phonimized.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5294d18-d0d0-4f85-856d-c552aff110e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hendelsen skjer tall_2. juni, og jeg kjøpte tall_5kg epler den tall_23/tall_10/tall_2024. Det kostet tall_10kroner.\n"
     ]
    }
   ],
   "source": [
    "import pyparsing as pp\n",
    "import re\n",
    "\n",
    "# Helper functions for normalization\n",
    "def normalize_number(num_str):\n",
    "    # Only return \"tall_\" prefix if the number is standalone (not part of a date or measurement)\n",
    "    return f\"tall_{num_str}\"\n",
    "\n",
    "def normalize_date(date_str):\n",
    "    # Normalize Norwegian dates (e.g., \"23rd October\" -> \"23. oktober\" or similar)\n",
    "    if \"/\" in date_str:\n",
    "        # Handle slash-separated dates (dd/mm/yyyy)\n",
    "        return re.sub(r\"(\\d{1,2})/(\\d{1,2})/(\\d{4})\", r\"\\1.\\2.\\3\", date_str)\n",
    "    return re.sub(r'(\\d{1,2})\\.\\s*(\\w+)', r'\\1. \\2', date_str)  # Ensure proper spacing for dates like \"2. juni\"\n",
    "\n",
    "def normalize_measurement(measure_str):\n",
    "    # Normalize Norwegian measurements (e.g., \"10kg\" -> \"10 kilo\")\n",
    "    measurement_units = {\n",
    "        \"kg\": \"kilo\",\n",
    "        \"cm\": \"centimeter\",\n",
    "        \"m\": \"meter\",\n",
    "        \"g\": \"gram\",\n",
    "        \"km\": \"kilometer\",\n",
    "        \"mm\": \"millimeter\",\n",
    "        \"l\": \"liter\",\n",
    "        \"dl\": \"desiliter\",\n",
    "    }\n",
    "    num, unit = re.match(r\"(\\d+)([a-zA-Z]+)\", measure_str).groups()\n",
    "    return f\"{num} {measurement_units.get(unit, unit)}\"\n",
    "\n",
    "def normalize_abbreviation(abbr_str):\n",
    "    # Normalize Norwegian abbreviations (e.g., \"NB\" -> \"Norsk Bokmål\", \"kr\" -> \"kroner\")\n",
    "    abbreviations = {\n",
    "        \"NB\": \"Norsk Bokmål\",\n",
    "        \"NN\": \"Nynorsk\",\n",
    "        \"kr\": \"kroner\",\n",
    "        \"mrd\": \"milliarder\",\n",
    "        \"t\": \"tonn\",\n",
    "    }\n",
    "    return abbreviations.get(abbr_str, abbr_str)  # Use the abbreviation if no mapping exists\n",
    "\n",
    "# Main normalization function\n",
    "def normalize_text_with_custom_rules(text):\n",
    "    # Define grammars for different types of data in Norwegian\n",
    "\n",
    "    # Grammar for standalone numbers (integers and floats)\n",
    "    number = pp.Combine(pp.Word(pp.nums) + pp.Optional(pp.oneOf(\",.\") + pp.Word(pp.nums)))\n",
    "\n",
    "    # Grammar for dates in formats like \"2. juni\" or \"23/10/2024\"\n",
    "    date = pp.Combine(pp.Word(pp.nums) + \".\" + pp.White() + pp.Word(pp.alphas)) | pp.Regex(r\"\\d{1,2}/\\d{1,2}/\\d{4}\")\n",
    "\n",
    "    # Grammar for measurements like \"10kg\", \"5cm\", \"3.5m\" (with Norwegian decimal separators)\n",
    "    measurement = pp.Combine(pp.Word(pp.nums + \",.\") + pp.Word(pp.alphas))\n",
    "\n",
    "    # Grammar for common Norwegian abbreviations\n",
    "    abbreviation = pp.Word(pp.alphas, exact=2) | pp.Word(pp.alphas, exact=3)\n",
    "\n",
    "    # Set parse actions for each pattern\n",
    "    number.setParseAction(lambda t: normalize_number(t[0]))\n",
    "    date.setParseAction(lambda t: normalize_date(t[0]))\n",
    "    measurement.setParseAction(lambda t: normalize_measurement(t[0]))\n",
    "    abbreviation.setParseAction(lambda t: normalize_abbreviation(t[0]))\n",
    "\n",
    "    # Combine all patterns into one parser\n",
    "    parser = number | date | measurement | abbreviation\n",
    "\n",
    "    # Normalize the text using the parser\n",
    "    normalized_text = parser.transformString(text)\n",
    "\n",
    "    return normalized_text\n",
    "\n",
    "# Example usage\n",
    "text_to_normalize = \"Hendelsen skjer 2. juni, og jeg kjøpte 5kg epler den 23/10/2024. Det kostet 10kr.\"\n",
    "normalized = normalize_text_with_custom_rules(text_to_normalize)\n",
    "print(normalized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff3a4309-e9c8-446d-bfed-949a3dee48b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted word combinations: ['5kg']\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Extract word combinations using pyparsing\n",
    "import pyparsing as pp\n",
    "import re\n",
    "\n",
    "# Helper function to extract only valid word combinations\n",
    "import pyparsing as pp\n",
    "import re\n",
    "\n",
    "# Helper function to extract only valid word combinations\n",
    "def extract_word_combinations(text):\n",
    "    word_combinations = []\n",
    "\n",
    "    # Define parsers for specific word combinations\n",
    "    \n",
    "    # Date parser (Norwegian date format and slash-separated dates)\n",
    "    date = pp.Combine(pp.Word(pp.nums) + \".\" + pp.White() + pp.Word(pp.alphas)) | pp.Regex(r\"\\d{1,2}/\\d{1,2}/\\d{4}\")\n",
    "\n",
    "    # Measurement parser (numbers followed by units like 'kg', 'cm')\n",
    "    measurement = pp.Combine(pp.Word(pp.nums + \",.\") + pp.Word(pp.alphas))\n",
    "\n",
    "    # Abbreviation parser: Only specific known abbreviations (like 'kr', 'mrd') \n",
    "    abbreviation = pp.Combine(pp.Word(\"kr\") | pp.Word(\"mrd\"))\n",
    "\n",
    "    # Standalone number parser (to match numbers not part of dates or measurements)\n",
    "    number = pp.Combine(pp.Word(pp.nums) + pp.Optional(pp.oneOf(\",.\") + pp.Word(pp.nums)))\n",
    "\n",
    "    # Combine all parsers into one\n",
    "    combined_parser = date | measurement | abbreviation | number\n",
    "\n",
    "    # Apply the parser with WordBoundary to ensure standalone matches\n",
    "    standalone_parser = pp.WordStart() + combined_parser + pp.WordEnd()\n",
    "\n",
    "    # Collect word combinations for conversion\n",
    "    for match, start, end in standalone_parser.scanString(text):\n",
    "        word_combinations.append(match[0])\n",
    "\n",
    "    # Remove duplicates by converting to a set and back to a list (maintain original order)\n",
    "    word_combinations = list(dict.fromkeys(word_combinations))\n",
    "\n",
    "    return word_combinations\n",
    "\n",
    "# Example usage to check what we are extracting\n",
    "text_to_normalize = \"Hendelsen skjer 2. juni, og jeg kjøpte 5kg epler den 23/10/2024. Det kostet 10kr.\"\n",
    "word_combinations = extract_word_combinations(text_to_normalize)\n",
    "print(\"Extracted word combinations:\", word_combinations)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973f2a79-0ed9-4ebc-a156-2dfc314f9a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_text_in_dict(input_file_path, output_file_path, k=100):\n",
    "    original_texts = {}\n",
    "    with open(input_file_path, 'r', encoding='utf-8') as infile, open(output_file_path, 'w', encoding='utf-8') as outfile:\n",
    "        for i, line in enumerate(infile):\n",
    "            # Split the line into audio_path, text, and speaker_nr\n",
    "            columns = line.split('|')\n",
    "\n",
    "            # Normalize the second column (text)\n",
    "            original_text = columns[1].strip()\n",
    "            \n",
    "\n",
    "            # Stop after processing `k` lines (if required)\n",
    "            if (i + 1) >= k:\n",
    "                break\n",
    "            original_texts\n",
    "\n",
    "\n",
    "    return original_texts\n",
    "\n",
    "\n",
    "# Call the function and create the comparison DataFrame\n",
    "df = get_all_text_in_dict('outputbooks.txt' , 'normalized.txt', k=5000)\n",
    "\n",
    "# Convert DataFrame to markdown format\n",
    "markdown_table = df.to_markdown(index=True)\n",
    "display(Markdown(markdown_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "879277e1-7bbb-479b-a973-50e5c4f600fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Input Tokens: 174462\n",
      "Total Output Tokens: 174462\n",
      "Estimated Input Cost: $ 0.01\n",
      "Estimated Output Cost: $ 0.05\n",
      "Estimated Total Cost: $ 0.07\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "# Updated GPT-4o mini pricing constants\n",
    "COST_PER_1M_INPUT_TOKENS = 0.150  # Uncached input cost\n",
    "COST_PER_1M_OUTPUT_TOKENS = 0.600  # Uncached output cost\n",
    "\n",
    "BATCH_API_COST_PER_1M_INPUT_TOKENS = 0.075  # Batch API input cost\n",
    "BATCH_API_COST_PER_1M_OUTPUT_TOKENS = 0.300  # Batch API output cost\n",
    "\n",
    "# Function to calculate token usage and estimate costs\n",
    "def get_all_text_in_dict(input_file_path, k=100, model=\"gpt-4o-mini\", use_batch_api=False):\n",
    "    \"\"\"\n",
    "    Reads a file line by line, extracts text, and estimates tokens using tiktoken.\n",
    "    Calculates the input/output tokens and estimates the cost for OpenAI API usage.\n",
    "\n",
    "    Params:\n",
    "    - input_file_path: Path to the input file with lines of text.\n",
    "    - k: Maximum number of lines to process.\n",
    "    - use_batch_api: Set to True if using Batch API pricing.\n",
    "    \n",
    "    Returns:\n",
    "    - original_texts: A dictionary where the key is the line number and the value is the text.\n",
    "    - token_info: A dictionary with total input and output tokens and estimated cost.\n",
    "    \"\"\"\n",
    "    original_texts = {}\n",
    "    total_input_tokens = 0\n",
    "    total_output_tokens = 0\n",
    "\n",
    "    # Get tokenizer for the specified model\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "\n",
    "    with open(input_file_path, 'r', encoding='utf-8') as infile:\n",
    "        for i, line in enumerate(infile):\n",
    "            # Split the line into components (assuming '|' delimiter)\n",
    "            columns = line.split('|')\n",
    "\n",
    "            # Ensure there's at least two columns in each line (one for text)\n",
    "            if len(columns) >= 2:\n",
    "                original_text = columns[1].strip()  # Extract the text (2nd column)\n",
    "\n",
    "                # Calculate input tokens using tiktoken for the text\n",
    "                input_tokens = encoding.encode(original_text)\n",
    "                num_input_tokens = len(input_tokens)\n",
    "                total_input_tokens += num_input_tokens\n",
    "\n",
    "                # Assume a 1:1 ratio for input to output tokens (modify if output varies)\n",
    "                num_output_tokens = num_input_tokens\n",
    "                total_output_tokens += num_output_tokens\n",
    "\n",
    "                # Store the original text with line number as the key\n",
    "                original_texts[i + 1] = original_text\n",
    "\n",
    "                # Stop after processing `k` lines if limit is reached\n",
    "                if (i + 1) >= k:\n",
    "                    break\n",
    "\n",
    "    # Choose pricing based on whether Batch API is used\n",
    "    input_cost_per_million = BATCH_API_COST_PER_1M_INPUT_TOKENS if use_batch_api else COST_PER_1M_INPUT_TOKENS\n",
    "    output_cost_per_million = BATCH_API_COST_PER_1M_OUTPUT_TOKENS if use_batch_api else COST_PER_1M_OUTPUT_TOKENS\n",
    "\n",
    "    # Calculate cost for input and output tokens\n",
    "    input_cost = (total_input_tokens / 1_000_000) * input_cost_per_million\n",
    "    output_cost = (total_output_tokens / 1_000_000) * output_cost_per_million\n",
    "    total_cost = input_cost + output_cost\n",
    "\n",
    "    # Token and cost summary\n",
    "    token_info = {\n",
    "        'total_input_tokens': total_input_tokens,\n",
    "        'total_output_tokens': total_output_tokens,\n",
    "        'input_cost': input_cost,\n",
    "        'output_cost': output_cost,\n",
    "        'total_cost': total_cost\n",
    "    }\n",
    "\n",
    "    return original_texts, token_info\n",
    "\n",
    "# Example usage\n",
    "input_file = 'outputbooks.txt'\n",
    "original_texts, token_info = get_all_text_in_dict(input_file, k=5000, use_batch_api=True)\n",
    "\n",
    "# Display token and cost analysis\n",
    "print(\"Total Input Tokens:\", token_info['total_input_tokens'])\n",
    "print(\"Total Output Tokens:\", token_info['total_output_tokens'])\n",
    "print(\"Estimated Input Cost: $\", round(token_info['input_cost'], 2))\n",
    "print(\"Estimated Output Cost: $\", round(token_info['output_cost'], 2))\n",
    "print(\"Estimated Total Cost: $\", round(token_info['total_cost'], 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2531fa4d-47b6-4ee4-b55d-30cf5b91742b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: openai: command not found\n"
     ]
    }
   ],
   "source": [
    "!openai migrate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88287d7b-b5ea-4569-8cf6-f9b36b694c92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42003b3c-073c-4c22-8be3-32b7b03d1f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from openai import OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "748a0a18-a843-4f3d-833e-a85327d46b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hendelsen skjer 2. juni, og jeg kjøpte 5kg epler den 23/10/2024. Det kostet 10kr.\n",
      "----\n",
      "Andelen empatiske eller veldig empatiske svar var 45,1 prosent hos ChatGPT, mot 4,6 prosent hos legene.\n",
      "----\n",
      "foretrakk dommerpanelet ChatGPT sitt svar i 78,6 prosent av tilfellene, og andelen vurderinger beskrevet som gode og veldig gode var 78,5 prosent for ChatGPT mot 22,1 prosent for legene.\n",
      "Response from model:\n",
      " Hendelsen skjer den andre juni, og jeg kjøpte fem kilo epler den tjue tredje oktober to tusen og tjue fire. Det kostet ti kroner.\n",
      "----\n",
      "Andelen empatiske eller veldig empatiske svar var førtifem komma én prosent hos ChatGPT, mot fire komma seks prosent hos legene.\n",
      "----\n",
      "Dommerpanelet foretrakk ChatGPT sitt svar i syttiatte komma seks prosent av tilfellene, og andelen vurderinger beskrevet som gode og veldig gode var syttiatte komma fem prosent for ChatGPT mot tjue to komma én prosent for legene.\n",
      "Results saved to normalized_output.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "def normalize_texts_with_gpt_and_save(texts, output_file, client, model=\"gpt-4o-mini\", batch_size=5):\n",
    "    \"\"\"\n",
    "    Sends batches of texts to GPT-4 mini for normalization and saves the results to a text file.\n",
    "    \n",
    "    Params:\n",
    "    - texts: List of text strings to normalize.\n",
    "    - output_file: File path to save the normalized results.\n",
    "    - client: The OpenAI client instance.\n",
    "    - model: The model to use (e.g., 'gpt-4o-mini').\n",
    "    - batch_size: Number of texts to send in each API call.\n",
    "    \n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    \n",
    "    # Prepare output file to save results\n",
    "    with open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "        # Process texts in batches\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch = texts[i:i + batch_size]\n",
    "            \n",
    "            # Join the batch with a separator (e.g., \"----\") to distinguish between texts\n",
    "            prompt = \"\\n----\\n\".join(batch)  \n",
    "            print(prompt)\n",
    "            # Make the API call to GPT-4 mini once per batch\n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"\"\"\n",
    "                    \n",
    "I want you to act as a text-normalizer for Norwegian. I will provide multiple instances containing dates, times, numbers, or other abbreviations, and you will convert each of them into their full, orthographically correct Norwegian forms. Please convert all numbers to their written form and do not include any explanations or additional information in your responses.\n",
    "\n",
    "For example:\n",
    "Input:\n",
    "Hendelsen skjer 2. juni, og jeg kjøpte 5kg epler den 23/10/2024. Det kostet 10kr.\n",
    "----\n",
    "Andelen empatiske eller veldig empatiske svar var 45,1 prosent hos ChatGPT, mot 4,6 prosent hos legene.\n",
    "----\n",
    "foretrakk dommerpanelet ChatGPT sitt svar i 78,6 prosent av tilfellene, og andelen vurderinger beskrevet som gode og veldig gode var 78,5 prosent for ChatGPT mot 22,1 prosent for legene.\n",
    "\n",
    "Output:\n",
    "Hendelsen skjer den andre juni, og jeg kjøpte fem kilo epler den tjue tredje oktober to tusen og tjue fire. Det kostet ti kroner.\n",
    "----\n",
    "Andelen empatiske eller veldig empatiske svar var førtifem komma én prosent hos ChatGPT, mot fire komma seks prosent hos legene.\n",
    "----\n",
    "Dommerpanelet foretrakk ChatGPT sitt svar i syttiatte komma seks prosent av tilfellene, og andelen vurderinger beskrevet som gode og veldig gode var syttiatte komma fem prosent for ChatGPT mot tjue to komma én prosent for legene.\"\n",
    "\"\"\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                max_tokens=2000,  # Adjust based on expected output size\n",
    "                temperature=0.0  # Set to 0 for deterministic outputs\n",
    "            )\n",
    "            \n",
    "            # Extract the response text and split based on the separator \"----\"\n",
    "            normalized_text = response.choices[0].message.content\n",
    "            print(\"Response from model:\\n\", normalized_text)\n",
    "\n",
    "            normalized_texts = normalized_text.split(\"\\n----\\n\")\n",
    "            \n",
    "            # Write each normalized text to the output file\n",
    "            outfile.write(normalized_text.strip() + \"\\n\")\n",
    "\n",
    "            \n",
    "    print(f\"Results saved to {output_file}\")\n",
    "\n",
    "# Example usage\n",
    "texts = [\n",
    "    \"Hendelsen skjer 2. juni, og jeg kjøpte 5kg epler den 23/10/2024. Det kostet 10kr.\",\n",
    "    \"Andelen empatiske eller veldig empatiske svar var 45,1 prosent hos ChatGPT, mot 4,6 prosent hos legene.\",\n",
    "    \"foretrakk dommerpanelet ChatGPT sitt svar i 78,6 prosent av tilfellene, og andelen vurderinger beskrevet som gode og veldig gode var 78,5 prosent for ChatGPT mot 22,1 prosent for legene.\",\n",
    "]\n",
    "\n",
    "normalize_texts_with_gpt_and_save(texts, 'normalized_output.txt', client)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6712e258-aa18-4440-adbb-f83e829ce59b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d913b5aa-3b2e-43d5-a02b-c9883b474100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio Path: 34_Dr_Chat_GPT_med_legelisens_133.wav\n",
      "Original Text: Det var mange som ble overrasket over resultatene til ChatGPT i denne studien.\n",
      "Normalized Text: Det var mange som ble overrasket over resultatene til ChatGPT i denne studien.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 34_Dr_Chat_GPT_med_legelisens_135.wav\n",
      "Original Text: foretrakk dommerpanelet ChatGPT sitt svar i 78,6 prosent av tilfellene, og andelen vurderinger beskrevet som gode og veldig gode var 78,5 prosent for ChatGPT mot 22,1 prosent for legene.\n",
      "Normalized Text: Foretrakk dommerpanelet ChatGPT sitt svar i åttiseks komma seks prosent av tilfellene, og andelen vurderinger beskrevet som gode og veldig gode var åttiseks komma fem prosent for ChatGPT mot toogtyve komma en prosent for legene.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 34_Dr_Chat_GPT_med_legelisens_136.wav\n",
      "Original Text: Men det aller mest oppsiktsvekkende var at forskjellen var enda større for vurderingen av empati i svarene.\n",
      "Normalized Text: Men det aller mest oppsiktsvekkende var at forskjellen var enda større for vurderingen av empati i svarene.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 34_Dr_Chat_GPT_med_legelisens_138.wav\n",
      "Original Text: Andelen empatiske eller veldig empatiske svar var 45,1 prosent hos ChatGPT, mot 4,6 prosent hos legene.\n",
      "Normalized Text: Andelen empatiske eller veldig empatiske svar var femogførti komma én prosent hos ChatGPT, mot fire komma seks prosent hos legene.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 34_Dr_Chat_GPT_med_legelisens_139.wav\n",
      "Original Text: Og ikke helt overraskende var legene svar en god del kortere i lengde, noe som kan forklares med at legene er presset på tid og har mange oppgaver.\n",
      "Normalized Text: Og ikke helt overraskende var legene svar en god del kortere i lengde, noe som kan forklares med at legene er presset på tid og har mange oppgaver.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 34_Dr_Chat_GPT_med_legelisens_140.wav\n",
      "Original Text: Kanskje må vi lære av ChatGPT, slik at vi kan bli enda bedre og mer empatiske leger.\n",
      "Normalized Text: Kanskje må vi lære av ChatGPT, slik at vi kan bli enda bedre og mer empatiske leger.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 11_Kunstig_intelligens_menneskets_beste_2.wav\n",
      "Original Text: Vi var tidligere innom definisjonen på kunstig intelligens slik den står i den norske strategien for kunstig intelligens fra 2020.\n",
      "Normalized Text: Vi var tidligere innom definisjonen på kunstig intelligens slik den står i den norske strategien for kunstig intelligens fra to tusen og tjue.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 11_Kunstig_intelligens_menneskets_beste_3.wav\n",
      "Original Text: Men en annen definisjon av kunstig intelligens lyder intelligent oppførsel i kunstig materie.\n",
      "Normalized Text: Men en annen definisjon av kunstig intelligens lyder intelligent oppførsel i kunstig materie.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 11_Kunstig_intelligens_menneskets_beste_4.wav\n",
      "Original Text: Altså noe annet enn den intelligensen som kommer med følelser og bevissthet som vi ser hos dyr og mennesker.\n",
      "Normalized Text: Altså noe annet enn den intelligensen som kommer med følelser og bevissthet som vi ser hos dyr og mennesker.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 11_Kunstig_intelligens_menneskets_beste_5.wav\n",
      "Original Text: Dessverre er denne definisjonen avhengig av at vi alle er enige om hva som er intelligent, og mange blir på grensen til provosert når dagens systemer for bilkjøring, ruteplanlegging og ansiktsgjenkjenning selges som kunstig intelligens.\n",
      "Normalized Text: Dessverre er denne definisjonen avhengig av at vi alle er enige om hva som er intelligent, og mange blir på grensen til provosert når dagens systemer for bilkjøring, ruteplanlegging og ansiktsgjenkjenning selges som kunstig intelligens.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "import re\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# A function to detect if a line needs normalization (dates, numbers, abbreviations, etc.)\n",
    "def needs_normalization(text):\n",
    "    # Regular expression to detect numbers, dates, abbreviations, etc.\n",
    "    pattern = r'\\b\\d{1,2}(?:\\.|/)\\d{1,2}(?:\\.|/)\\d{2,4}|\\d+(?:kr|kg|%)|\\b\\d+\\b'\n",
    "    \n",
    "    # If the pattern is found in the text, normalization might be needed\n",
    "    return re.search(pattern, text) is not None\n",
    "\n",
    "def get_all_text_in_dict(input_file_path, output_file_path, client, model=\"gpt-4o-mini\", k=10):\n",
    "    \"\"\"\n",
    "    Reads the input file, normalizes the second column (text) using GPT-4 mini if needed, and saves the results to the output file.\n",
    "    \n",
    "    Params:\n",
    "    - input_file_path: Path to the input file containing audio_path, text, and speaker_nr.\n",
    "    - output_file_path: Path to the output file where normalized text will be saved.\n",
    "    - client: OpenAI client instance for making API requests.\n",
    "    - model: The model to use for normalization (default: 'gpt-4o-mini').\n",
    "    - k: Maximum number of lines to process.\n",
    "    \n",
    "    Returns:\n",
    "    - processed_texts: A dictionary of the processed texts where keys are audio_path, and values are dictionaries with 'original_text', 'normalized_text', and 'speaker_nr'.\n",
    "    \"\"\"\n",
    "    processed_texts = {}\n",
    "    \n",
    "    # Open the input and output files\n",
    "    with open(input_file_path, 'r', encoding='utf-8') as infile, open(output_file_path, 'w', encoding='utf-8') as outfile:\n",
    "        \n",
    "        for i, line in enumerate(infile):\n",
    "            # Split the line into audio_path, text, and speaker_nr\n",
    "            columns = line.split('|')\n",
    "            if len(columns) < 3:\n",
    "                continue  # Skip lines that do not have all columns\n",
    "            \n",
    "            audio_path = columns[0].strip()\n",
    "            original_text = columns[1].strip()\n",
    "            speaker_nr = columns[2].strip()\n",
    "            \n",
    "            # Check if the text needs normalization\n",
    "            if needs_normalization(original_text):\n",
    "                # If normalization is needed, call the OpenAI API\n",
    "                response = client.chat.completions.create(\n",
    "                    model=model,\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": \"I want you to act as a text-normalizer for Norwegian. I will provide dates, times, numbers, or other abbreviations, and you will convert them into their full, orthographically correct Norwegian forms. Please convert all numbers to their written form and do not include any explanations or additional information in your responses.\"},\n",
    "                        {\"role\": \"user\", \"content\": original_text}\n",
    "                    ],\n",
    "                    max_tokens=2000,\n",
    "                    temperature=0.0\n",
    "                )\n",
    "                \n",
    "                # Extract the normalized text\n",
    "                normalized_text = response.choices[0].message.content.strip()\n",
    "            else:\n",
    "                # If no normalization is needed, keep the original text\n",
    "                normalized_text = original_text\n",
    "            \n",
    "            # Write the normalized (or original) text back to the output file and save to dictionary\n",
    "            outfile.write(f\"{audio_path}|{normalized_text}|{speaker_nr}\\n\")\n",
    "            \n",
    "            # Store the processed result in the dictionary\n",
    "            processed_texts[audio_path] = {\n",
    "                'original_text': original_text,\n",
    "                'normalized_text': normalized_text,\n",
    "                'speaker_nr': speaker_nr\n",
    "            }\n",
    "            \n",
    "            # Stop after processing `k` lines (if required)\n",
    "            if (i + 1) >= k:\n",
    "                break\n",
    "\n",
    "    return processed_texts\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI(api_key='')\n",
    "\n",
    "# Example usage\n",
    "input_file_path = 'outputbooks.txt'\n",
    "output_file_path = 'normalized_output.txt'\n",
    "processed_data = get_all_text_in_dict(input_file_path, output_file_path, client)\n",
    "\n",
    "# Print the returned data for verification\n",
    "for audio_path, data in processed_data.items():\n",
    "    print(f\"Audio Path: {audio_path}\")\n",
    "    print(f\"Original Text: {data['original_text']}\")\n",
    "    print(f\"Normalized Text: {data['normalized_text']}\")\n",
    "    print(f\"Speaker Number: {data['speaker_nr']}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "348c6ccf-4ab4-42d5-b86e-76697d164398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio Path: 34_Dr_Chat_GPT_med_legelisens_133.wav\n",
      "Original Text: Det var mange som ble overrasket over resultatene til ChatGPT i denne studien.\n",
      "Normalized Text: Det var mange som ble overrasket over resultatene til ChatGPT i denne studien.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 34_Dr_Chat_GPT_med_legelisens_135.wav\n",
      "Original Text: foretrakk dommerpanelet ChatGPT sitt svar i 78,6 prosent av tilfellene, og andelen vurderinger beskrevet som gode og veldig gode var 78,5 prosent for ChatGPT mot 22,1 prosent for legene.\n",
      "Normalized Text: Foretrakk dommerpanelet ChatGPT sitt svar i åttiseks komma seks prosent av tilfellene, og andelen vurderinger beskrevet som gode og veldig gode var åttiseks komma fem prosent for ChatGPT mot toogtyve komma en prosent for legene.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 34_Dr_Chat_GPT_med_legelisens_136.wav\n",
      "Original Text: Men det aller mest oppsiktsvekkende var at forskjellen var enda større for vurderingen av empati i svarene.\n",
      "Normalized Text: Men det aller mest oppsiktsvekkende var at forskjellen var enda større for vurderingen av empati i svarene.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 34_Dr_Chat_GPT_med_legelisens_138.wav\n",
      "Original Text: Andelen empatiske eller veldig empatiske svar var 45,1 prosent hos ChatGPT, mot 4,6 prosent hos legene.\n",
      "Normalized Text: Andelen empatiske eller veldig empatiske svar var femogførti komma én prosent hos ChatGPT, mot fire komma seks prosent hos legene.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 34_Dr_Chat_GPT_med_legelisens_139.wav\n",
      "Original Text: Og ikke helt overraskende var legene svar en god del kortere i lengde, noe som kan forklares med at legene er presset på tid og har mange oppgaver.\n",
      "Normalized Text: Og ikke helt overraskende var legene svar en god del kortere i lengde, noe som kan forklares med at legene er presset på tid og har mange oppgaver.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 34_Dr_Chat_GPT_med_legelisens_140.wav\n",
      "Original Text: Kanskje må vi lære av ChatGPT, slik at vi kan bli enda bedre og mer empatiske leger.\n",
      "Normalized Text: Kanskje må vi lære av ChatGPT, slik at vi kan bli enda bedre og mer empatiske leger.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 11_Kunstig_intelligens_menneskets_beste_2.wav\n",
      "Original Text: Vi var tidligere innom definisjonen på kunstig intelligens slik den står i den norske strategien for kunstig intelligens fra 2020.\n",
      "Normalized Text: Vi var tidligere innom definisjonen på kunstig intelligens slik den står i den norske strategien for kunstig intelligens fra to tusen og tjue.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 11_Kunstig_intelligens_menneskets_beste_3.wav\n",
      "Original Text: Men en annen definisjon av kunstig intelligens lyder intelligent oppførsel i kunstig materie.\n",
      "Normalized Text: Men en annen definisjon av kunstig intelligens lyder intelligent oppførsel i kunstig materie.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 11_Kunstig_intelligens_menneskets_beste_4.wav\n",
      "Original Text: Altså noe annet enn den intelligensen som kommer med følelser og bevissthet som vi ser hos dyr og mennesker.\n",
      "Normalized Text: Altså noe annet enn den intelligensen som kommer med følelser og bevissthet som vi ser hos dyr og mennesker.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 11_Kunstig_intelligens_menneskets_beste_5.wav\n",
      "Original Text: Dessverre er denne definisjonen avhengig av at vi alle er enige om hva som er intelligent, og mange blir på grensen til provosert når dagens systemer for bilkjøring, ruteplanlegging og ansiktsgjenkjenning selges som kunstig intelligens.\n",
      "Normalized Text: Dessverre er denne definisjonen avhengig av at vi alle er enige om hva som er intelligent, og mange blir på grensen til provosert når dagens systemer for bilkjøring, ruteplanlegging og ansiktsgjenkjenning selges som kunstig intelligens.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 11_Kunstig_intelligens_menneskets_beste_6.wav\n",
      "Original Text: Og samtidig som ekspertene er uenige om kun en felles definisjon av kunstig intelligens, er begrepet kunstig intelligens også navnet på et relativt ungt fag.\n",
      "Normalized Text: Og samtidig som ekspertene er uenige om kun en felles definisjon av kunstig intelligens, er begrepet kunstig intelligens også navnet på et relativt ungt fag.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 11_Kunstig_intelligens_menneskets_beste_7.wav\n",
      "Original Text: Kunstig intelligens er et akademisk fagfelt som ble grunnlagt på en amerikansk konferanse i 1956.\n",
      "Normalized Text: Kunstig intelligens er et akademisk fagfelt som ble grunnlagt på en amerikansk konferanse i nitten femti-seks.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 11_Kunstig_intelligens_menneskets_beste_8.wav\n",
      "Original Text: Å kunne tidfeste når et fagfelt ble født så nøyaktig er unikt, men det er altså tilfelle med kunstig intelligens, i motsetning til medisin og medisinsk praksis som har eksistert i mange tusener av år og uten en spesifik startdato.\n",
      "Normalized Text: Å kunne tidfeste når et fagfelt ble født så nøyaktig er unikt, men det er altså tilfelle med kunstig intelligens, i motsetning til medisin og medisinsk praksis som har eksistert i mange tusener av år og uten en spesifik startdato.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 11_Kunstig_intelligens_menneskets_beste_9.wav\n",
      "Original Text: Helt siden 1956 har fagområdet kunstig intelligens handlet om å få maskiner til å oppføre seg intelligent,\n",
      "Normalized Text: Helt siden nitten femti-seks har fagområdet kunstig intelligens handlet om å få maskiner til å oppføre seg intelligent.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 11_Kunstig_intelligens_menneskets_beste_12.wav\n",
      "Original Text: Telefonen har lært seg hvordan du ser ut, først gjennom assistert trening, og så av erfaring gjennom bruk.\n",
      "Normalized Text: Telefonen har lært seg hvordan du ser ut, først gjennom assistert trening, og så av erfaring gjennom bruk.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 11_Kunstig_intelligens_menneskets_beste_13.wav\n",
      "Original Text: Likevel føler de færrest av oss at vi kommuniserer med et intelligent vesen når vi fikler med telefonen.\n",
      "Normalized Text: Likevel føler de færrest av oss at vi kommuniserer med et intelligent vesen når vi fikler med telefonen.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 11_Kunstig_intelligens_menneskets_beste_14.wav\n",
      "Original Text: Det er ikke godt å si hvordan pionerene som grunnla fagfeltet kunstig intelligens i 1950-årene hadde reagert i møte med verden i dag, der en maskin kan både gjenkjenne ansikter, komponere musikk og kjøre bil.\n",
      "Normalized Text: Det er ikke godt å si hvordan pionerene som grunnla fagfeltet kunstig intelligens i nitten femtiårene hadde reagert i møte med verden i dag, der en maskin kan både gjenkjenne ansikter, komponere musikk og kjøre bil.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 11_Kunstig_intelligens_menneskets_beste_16.wav\n",
      "Original Text: Men vi som omgir oss med denne teknologien hver dag, tenker nok at ansiktsgjenkjenning i en telefon ikke er det samme som å være intelligent, eller å forstå hva et ansikt er, hva noe enn det betyr.\n",
      "Normalized Text: Men vi som omgir oss med denne teknologien hver dag, tenker nok at ansiktsgjenkjenning i en telefon ikke er det samme som å være intelligent, eller å forstå hva et ansikt er, hva noe enn det betyr.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 11_Kunstig_intelligens_menneskets_beste_17.wav\n",
      "Original Text: Når vi tenker slik, demonstrerer vi faktisk et fenomen som er så vanlig at det har fått et navn.\n",
      "Normalized Text: Når vi tenker slik, demonstrerer vi faktisk et fenomen som er så vanlig at det har fått et navn.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 11_Kunstig_intelligens_menneskets_beste_18.wav\n",
      "Original Text: Det kalles The AI Effect, og det beskriver et gammelt fenomen innen utvikling av kunstig intelligens.\n",
      "Normalized Text: Det kalles The AI Effect, og det beskriver et gammelt fenomen innen utvikling av kunstig intelligens.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 11_Kunstig_intelligens_menneskets_beste_20.wav\n",
      "Original Text: Spiller sjakk, kjører bil, gjenkjenner en katt på et bilde, er reaksjonen «Det der er ikke intelligens.\n",
      "Normalized Text: Spiller sjakk, kjører bil, gjenkjenner en katt på et bilde, er reaksjonen «Det der er ikke intelligens.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 11_Kunstig_intelligens_menneskets_beste_22.wav\n",
      "Original Text: Så vanlig er dette at flere av mine legekolleger som forsket på andre medisinske felt og ikke på AI, ofte kom med utsang som «Det er vel ikke noe intelligent med det å gjenkjenne polyper.\n",
      "Normalized Text: Så vanlig er dette at flere av mine legekolleger som forsket på andre medisinske felt og ikke på AI, ofte kom med utsang som «Det er vel ikke noe intelligent med det å gjenkjenne polyper.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 11_Kunstig_intelligens_menneskets_beste_25.wav\n",
      "Original Text: Det kan derfor hende at ideen om kunstig intelligens alltid vil forbli noe vi dytter foran oss, og at den består av alt vi ikke forventer at en datamaskin kan gjøre.\n",
      "Normalized Text: Det kan derfor hende at ideen om kunstig intelligens alltid vil forbli noe vi dytter foran oss, og at den består av alt vi ikke forventer at en datamaskin kan gjøre.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 11_Kunstig_intelligens_menneskets_beste_26.wav\n",
      "Original Text: En vits i AI-miljøet lyder slik, og er ganske treffende for fenomenet.\n",
      "Normalized Text: En vits i AI-miljøet lyder slik, og er ganske treffende for fenomenet.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 11_Kunstig_intelligens_menneskets_beste_28.wav\n",
      "Original Text: Likevel hører vi at det finnes kunstig intelligens i banker, hos forsikringsselskaper, på søkemotorer, og strengt tatt også i telefonene våre.\n",
      "Normalized Text: Likevel hører vi at det finnes kunstig intelligens i banker, hos forsikringsselskaper, på søkemotorer, og strengt tatt også i telefonene våre.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 11_Kunstig_intelligens_menneskets_beste_29.wav\n",
      "Original Text: Det er fordi kunstig intelligens, i tillegg til å være et fagfelt, også er en samlebetegnelse.\n",
      "Normalized Text: Det er fordi kunstig intelligens, i tillegg til å være et fagfelt, også er en samlebetegnelse.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 11_Kunstig_intelligens_menneskets_beste_30.wav\n",
      "Original Text: Den er en stor sekk som inneholder mange ulike begreper, som beskriver strategier maskiner kan bruke for å løse problemer.\n",
      "Normalized Text: Den er en stor sekk som inneholder mange ulike begreper, som beskriver strategier maskiner kan bruke for å løse problemer.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 11_Kunstig_intelligens_menneskets_beste_32.wav\n",
      "Original Text: Og hvis du fulgte med på nyhetene i 1997, kan det hende at du fikk med deg en spesiell hendelse hvor bruken av et slikt ekspertsystem var sentral.\n",
      "Normalized Text: Og hvis du fulgte med på nyhetene i nitten nittisju, kan det hende at du fikk med deg en spesiell hendelse hvor bruken av et slikt ekspertsystem var sentral.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 11_Kunstig_intelligens_menneskets_beste_33.wav\n",
      "Original Text: Det året klarte NASA for første gang å få en ubemannet motorisert landfarkost, også kjent som en rover, til å lande på planeten Mars for å samle inn data.\n",
      "Normalized Text: Det året klarte NASA for første gang å få en ubemannet motorisert landfarkost, også kjent som en rover, til å lande på planeten Mars for å samle inn data.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 11_Kunstig_intelligens_menneskets_beste_34.wav\n",
      "Original Text: På grunn av den lange avstanden fra jorden til Mars var kommunikasjonstiden alt fra 5 til 20 minutter en vei, noe som gjorde at direkte kontroll av roveren var vanskelig.\n",
      "Normalized Text: På grunn av den lange avstanden fra jorden til Mars var kommunikasjonstiden alt fra fem til tjue minutter en vei, noe som gjorde at direkte kontroll av roveren var vanskelig.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 11_Kunstig_intelligens_menneskets_beste_35.wav\n",
      "Original Text: Derfor bestod slike rovere av blant annet ekspertsystemer, som var forhåndsprogrammert med instruksjoner om hvordan de skulle bevege seg fremover og hvordan samle inn data.\n",
      "Normalized Text: Derfor bestod slike rovere av blant annet ekspertsystemer, som var forhåndsprogrammert med instruksjoner om hvordan de skulle bevege seg fremover og hvordan samle inn data.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 11_Kunstig_intelligens_menneskets_beste_36.wav\n",
      "Original Text: Slike ekspertsystemer lages ved at mennesker skriver nøyaktige regler for hva systemet skal gjøre og når, og denne fremgangsmåten var lenge sett på som den mest lovende veien til kunstig intelligens.\n",
      "Normalized Text: Slike ekspertsystemer lages ved at mennesker skriver nøyaktige regler for hva systemet skal gjøre og når, og denne fremgangsmåten var lenge sett på som den mest lovende veien til kunstig intelligens.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 11_Kunstig_intelligens_menneskets_beste_38.wav\n",
      "Original Text: Hvis vi for eksempel skulle lære bort syklingens noble kunst til noen som aldri har sett en sykkel før, måtte vi forklart at rumpa skal være på setet, at hendene skal brukes til å styre retningen, at bena skal trokke rundt og rundt, og at balansen må fordeles nøyaktig slik at syklen ikke velter til siden.\n",
      "Normalized Text: Hvis vi for eksempel skulle lære bort syklingens noble kunst til noen som aldri har sett en sykkel før, måtte vi forklart at rumpa skal være på setet, at hendene skal brukes til å styre retningen, at bena skal trokke rundt og rundt, og at balansen må fordeles nøyaktig slik at syklen ikke velter til siden.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 11_Kunstig_intelligens_menneskets_beste_39.wav\n",
      "Original Text: På dette tidspunktet måtte vi nok ha hentet frem noen ligninger som beskriver sykkelfysikk.\n",
      "Normalized Text: På dette tidspunktet måtte vi nok ha hentet frem noen ligninger som beskriver sykkelfysikk.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 11_Kunstig_intelligens_menneskets_beste_41.wav\n",
      "Original Text: er det å få en forklaring på hvordan noe skal gjøres, slett ikke det samme som å forstå hvordan det skal gjøres, og det var neppe noen ligninger med fysikklover involvert da du lærte å sykle.\n",
      "Normalized Text: er det å få en forklaring på hvordan noe skal gjøres, slett ikke det samme som å forstå hvordan det skal gjøres, og det var neppe noen ligninger med fysikklover involvert da du lærte å sykle.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 11_Kunstig_intelligens_menneskets_beste_42.wav\n",
      "Original Text: Vi mennesker lærer det meste gjennom prøving på egenhånd, ikke fra detaljerte forklaringer.\n",
      "Normalized Text: Vi mennesker lærer det meste gjennom prøving på egenhånd, ikke fra detaljerte forklaringer.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 11_Kunstig_intelligens_menneskets_beste_44.wav\n",
      "Original Text: Å forklare en maskin nøyaktig hva noe er og hva den skal gjøre, er utrolig krevende og kanskje umulig.\n",
      "Normalized Text: Å forklare en maskin nøyaktig hva noe er og hva den skal gjøre, er utrolig krevende og kanskje umulig.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 11_Kunstig_intelligens_menneskets_beste_46.wav\n",
      "Original Text: Det er lett å se forskjell på en smiley og et menneskeansikt, men å forklare nøyaktig hva som utgjør et ansikt er en enorm utfordring.\n",
      "Normalized Text: Det er lett å se forskjell på en smiley og et menneskeansikt, men å forklare nøyaktig hva som utgjør et ansikt er en enorm utfordring.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 11_Kunstig_intelligens_menneskets_beste_47.wav\n",
      "Original Text: Slik gjenkjenning er et problem som forskere innen kunstig intelligens ikke klarer å løse, men heller må unngå.\n",
      "Normalized Text: Slik gjenkjenning er et problem som forskere innen kunstig intelligens ikke klarer å løse, men heller må unngå.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 11_Kunstig_intelligens_menneskets_beste_48.wav\n",
      "Original Text: Vi kan ikke lage intelligente maskiner som er avhengig av detaljerte instruksjoner fra mennesker for hver eneste situasjon de kan støte på.\n",
      "Normalized Text: Vi kan ikke lage intelligente maskiner som er avhengig av detaljerte instruksjoner fra mennesker for hver eneste situasjon de kan støte på.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 11_Kunstig_intelligens_menneskets_beste_50.wav\n",
      "Original Text: Problemet kan unngås ved hjelp av den tilnærmingen som har vunnet frem de siste 10-20 årene, som går ut på at maskinene finner ut av ting selv.\n",
      "Normalized Text: Problemet kan unngås ved hjelp av den tilnærmingen som har vunnet frem de siste ti til tjue årene, som går ut på at maskinene finner ut av ting selv.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 11_Kunstig_intelligens_menneskets_beste_51.wav\n",
      "Original Text: Maskinene må selv lære seg det de trenger å vite for å fungere og oppnå målene vi gir dem.\n",
      "Normalized Text: Maskinene må selv lære seg det de trenger å vite for å fungere og oppnå målene vi gir dem.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 11_Kunstig_intelligens_menneskets_beste_52.wav\n",
      "Original Text: Denne læringen kalles maskinlæring, og den er selve hovedgrunnen til at kunstig intelligens er blitt hippt igjen.\n",
      "Normalized Text: Denne læringen kalles maskinlæring, og den er selve hovedgrunnen til at kunstig intelligens er blitt hippt igjen.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 11_Kunstig_intelligens_menneskets_beste_54.wav\n",
      "Original Text: Siden fagfeltet kunstig intelligens oppstod i midten av 1950-årene, har det gjennomgått mange berg- og dalbaner av høye forventninger og store skuffelser.\n",
      "Normalized Text: Siden fagfeltet kunstig intelligens oppstod i midten av nitten femtiårene, har det gjennomgått mange berg- og dalbaner av høye forventninger og store skuffelser.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 11_Kunstig_intelligens_menneskets_beste_55.wav\n",
      "Original Text: Det som skjer nå er at alle snakker om kunstig intelligens, og at det knapt går en dag uten at vi kan lese om det i avisene.\n",
      "Normalized Text: Det som skjer nå er at alle snakker om kunstig intelligens, og at det knapt går en dag uten at vi kan lese om det i avisene.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 11_Kunstig_intelligens_menneskets_beste_56.wav\n",
      "Original Text: Og det som er nytt denne gangen er at teknologien har begynt å fungere skikkelig bra.\n",
      "Normalized Text: Og det som er nytt denne gangen er at teknologien har begynt å fungere skikkelig bra.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 15_l_re_maskiner_se_1.wav\n",
      "Original Text: Spørsmålet om hvordan maskiner skal bli i stand til å forstå hva de ser på, har forskere slitt med i over 60 år.\n",
      "Normalized Text: Spørsmålet om hvordan maskiner skal bli i stand til å forstå hva de ser på, har forskere slitt med i over seksti år.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 15_l_re_maskiner_se_3.wav\n",
      "Original Text: Hvis vi faktisk er på riktig spor, ligger løsningen i maskinlæring, og håpet hviler på skuldrene til nevrale nettverk.\n",
      "Normalized Text: Hvis vi faktisk er på riktig spor, ligger løsningen i maskinlæring, og håpet hviler på skuldrene til nevrale nettverk.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 15_l_re_maskiner_se_5.wav\n",
      "Original Text: Så modellen jeg bruker for å få hjelp til å oppdage polyper er av samme type som modellen telefonen din bruker for å gjenkjenne ansiktet ditt før den låser opp skjermen.\n",
      "Normalized Text: Så modellen jeg bruker for å få hjelp til å oppdage polyper er av samme type som modellen telefonen din bruker for å gjenkjenne ansiktet ditt før den låser opp skjermen.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 15_l_re_maskiner_se_6.wav\n",
      "Original Text: For å trene opp en maskinlæringsmodell som skal brukes innen helse, må domeneeksperter som leger og annet helsepersonell bidra til å lage et datasett.\n",
      "Normalized Text: For å trene opp en maskinlæringsmodell som skal brukes innen helse, må domeneeksperter som leger og annet helsepersonell bidra til å lage et datasett.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 15_l_re_maskiner_se_7.wav\n",
      "Original Text: Dette kan for eksempel være et datasett bestående av polypbilder som tidligere har blitt annotert, og når man har et datasett klart kan man gå løs på selve maskinlæringen.\n",
      "Normalized Text: Dette kan for eksempel være et datasett bestående av polypbilder som tidligere har blitt annotert, og når man har et datasett klart kan man gå løs på selve maskinlæringen.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 15_l_re_maskiner_se_9.wav\n",
      "Original Text: Treningsdata, valideringsdata og testdata.\n",
      "Normalized Text: Treningsdata, valideringsdata og testdata.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 15_l_re_maskiner_se_10.wav\n",
      "Original Text: Maskinlæringsmodellen trenes opp på treningsdata som utgjør den største delen av datasettet.\n",
      "Normalized Text: Maskinlæringsmodellen trenes opp på treningsdata som utgjør den største delen av datasettet.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 15_l_re_maskiner_se_12.wav\n",
      "Original Text: Så skal maskinlæringsmodellens ytelse valideres, det vil si vurderes på valideringsdataene for å se om modellen utvikler seg i riktig retning.\n",
      "Normalized Text: Så skal maskinlæringsmodellens ytelse valideres, det vil si vurderes på valideringsdataene for å se om modellen utvikler seg i riktig retning.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 15_l_re_maskiner_se_14.wav\n",
      "Original Text: Når man så har oppnådd ønsket ytelse, skal maskinlæringsmodellen testes på testdataene, som en slags siste eksamen for å forstå hvor godt maskinlæringsmodellen faktisk presterer.\n",
      "Normalized Text: Når man så har oppnådd ønsket ytelse, skal maskinlæringsmodellen testes på testdataene, som en slags siste eksamen for å forstå hvor godt maskinlæringsmodellen faktisk presterer.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 15_l_re_maskiner_se_15.wav\n",
      "Original Text: Det er viktig å huske på at testdataene ikke skal brukes før treningsfasen er avsluttet, fordi dette skal være et datasett som modellen aldri har sett før.\n",
      "Normalized Text: Det er viktig å huske på at testdataene ikke skal brukes før treningsfasen er avsluttet, fordi dette skal være et datasett som modellen aldri har sett før.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 15_l_re_maskiner_se_16.wav\n",
      "Original Text: Formålet med testdata er å evaluere hvor godt den endelige modellen vil prestere på nye, usette data, det vil si hvor godt den kan generalisere.\n",
      "Normalized Text: Formålet med testdata er å evaluere hvor godt den endelige modellen vil prestere på nye, usette data, det vil si hvor godt den kan generalisere.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 15_l_re_maskiner_se_17.wav\n",
      "Original Text: Når maskinlæringsmodellen omsider er ferdig trent, testet og godkjent, står vi igjen med et kunstig intelligent system av typen klinisk beslutningsstøtte, som kan bli med inn på behandlingsrommet og hjelpe meg som lege med å vurdere polyper.\n",
      "Normalized Text: Når maskinlæringsmodellen omsider er ferdig trent, testet og godkjent, står vi igjen med et kunstig intelligent system av typen klinisk beslutningsstøtte, som kan bli med inn på behandlingsrommet og hjelpe meg som lege med å vurdere polyper.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 15_l_re_maskiner_se_18.wav\n",
      "Original Text: Maskinlæringsmodellen, eller AI-verktøyet, vil ha en formening om hvorvidt jeg som den legen som undersøker pasienten med koloskope har funnet en polyp, eller om jeg kun har med vanlig tarmvev å gjøre.\n",
      "Normalized Text: Maskinlæringsmodellen, eller AI-verktøyet, vil ha en formening om hvorvidt jeg som den legen som undersøker pasienten med koloskope har funnet en polyp, eller om jeg kun har med vanlig tarmvev å gjøre.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 15_l_re_maskiner_se_19.wav\n",
      "Original Text: En stor fordel ved dette er at forskjeller mellom ulike leger kan utjevnes, noe som igjen kan forebygge skader eller feiltrin.\n",
      "Normalized Text: En stor fordel ved dette er at forskjeller mellom ulike leger kan utjevnes, noe som igjen kan forebygge skader eller feiltrin.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 15_l_re_maskiner_se_20.wav\n",
      "Original Text: Men det finnes også en større, mer subtil fordel, som kanskje illustreres best gjennom et eksempel fra sjakk.\n",
      "Normalized Text: Men det finnes også en større, mer subtil fordel, som kanskje illustreres best gjennom et eksempel fra sjakk.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 15_l_re_maskiner_se_21.wav\n",
      "Original Text: Verdens beste sjakkspillere heter i dag AlphaZero og Stockfish.\n",
      "Normalized Text: Verdens beste sjakkspillere heter i dag AlphaZero og Stockfish.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 15_l_re_maskiner_se_22.wav\n",
      "Original Text: Det er altså maskiner som er de beste sjakkspillerne, bedre enn mennesker.\n",
      "Normalized Text: Det er altså maskiner som er de beste sjakkspillerne, bedre enn mennesker.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 15_l_re_maskiner_se_23.wav\n",
      "Original Text: AlphaZero er et enormt nevralt nettverk som lærte seg å spille sjakk gjennom maskinlæring.\n",
      "Normalized Text: AlphaZero er et enormt nevralt nettverk som lærte seg å spille sjakk gjennom maskinlæring.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 15_l_re_maskiner_se_24.wav\n",
      "Original Text: Grunnen til at det har Zero i navnet er at det fikk Zero, altså ingen som helst informasjon om hva som er lurt å gjøre i sjakk før det begynte på treningen.\n",
      "Normalized Text: Grunnen til at det har Zero i navnet er at det fikk Zero, altså ingen som helst informasjon om hva som er lurt å gjøre i sjakk før det begynte på treningen.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 15_l_re_maskiner_se_26.wav\n",
      "Original Text: Men i stedet for å bli en veldig smart, men primitiv sjakkspiller, endte det opp med å oppdage strategier ingen mennesker kjente til.\n",
      "Normalized Text: Men i stedet for å bli en veldig smart, men primitiv sjakkspiller, endte det opp med å oppdage strategier ingen mennesker kjente til.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 15_l_re_maskiner_se_27.wav\n",
      "Original Text: Når stormester Garry Kasparov beskriver AlphaZero, sier han at tradisjonelle sjakkdatamaskiner er sterke og nesten aldri begår åpenbare feil, men at de sliter når de havner i posisjoner der det beste trekket ikke kan beregnes.\n",
      "Normalized Text: Når stormester Garry Kasparov beskriver AlphaZero, sier han at tradisjonelle sjakkdatamaskiner er sterke og nesten aldri begår åpenbare feil, men at de sliter når de havner i posisjoner der det beste trekket ikke kan beregnes.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 15_l_re_maskiner_se_28.wav\n",
      "Original Text: I slike posisjoner trengs følelse for spillet og intuisjon, som er nettopp det AlphaZero har.\n",
      "Normalized Text: I slike posisjoner trengs følelse for spillet og intuisjon, som er nettopp det AlphaZero har.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 15_l_re_maskiner_se_29.wav\n",
      "Original Text: Forskjellen på systemer vi mennesker mater med den informasjonen vi vet eller tror er riktig, og systemer som lærer selv gjennom maskinlæring, er altså potensielt enorm.\n",
      "Normalized Text: Forskjellen på systemer vi mennesker mater med den informasjonen vi vet eller tror er riktig, og systemer som lærer selv gjennom maskinlæring, er altså potensielt enorm.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 15_l_re_maskiner_se_33.wav\n",
      "Original Text: Maskinlæring kan hjelpe mennesker å oppdage ny kunnskap innen alle felt.\n",
      "Normalized Text: Maskinlæring kan hjelpe mennesker å oppdage ny kunnskap innen alle felt.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 15_l_re_maskiner_se_34.wav\n",
      "Original Text: Dette er store ord, men feltemedisin har samme mulighet ved bruk av maskinlæring.\n",
      "Normalized Text: Dette er store ord, men feltemedisin har samme mulighet ved bruk av maskinlæring.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 15_l_re_maskiner_se_35.wav\n",
      "Original Text: Håpet er at maskinlæringsmodeller skal finne ut noe vi mennesker ikke klarer, og utvikle en bedre intuisjon enn vi har.\n",
      "Normalized Text: Håpet er at maskinlæringsmodeller skal finne ut noe vi mennesker ikke klarer, og utvikle en bedre intuisjon enn vi har.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 15_l_re_maskiner_se_37.wav\n",
      "Original Text: Det er dessverre ikke bare å overføre et enormt datasett med bilder til en hvilken som helst maskinlæringsalgoritme, og forvente at evnen til bildigjenkjenning kommer ut på den andre siden.\n",
      "Normalized Text: Det er dessverre ikke bare å overføre et enormt datasett med bilder til en hvilken som helst maskinlæringsalgoritme, og forvente at evnen til bildigjenkjenning kommer ut på den andre siden.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 15_l_re_maskiner_se_38.wav\n",
      "Original Text: Gjennom 60 år har forskere forsøkt å finne ut hvordan maskiner skal lære seg å forstå hva de ser på bilder.\n",
      "Normalized Text: Gjennom seksti år har forskere forsøkt å finne ut hvordan maskiner skal lære seg å forstå hva de ser på bilder.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 15_l_re_maskiner_se_39.wav\n",
      "Original Text: Og det har vist seg at det trengs en helt spesiell oppbygning, altså en arkitektur av nevrale nettverk for å få det til.\n",
      "Normalized Text: Og det har vist seg at det trengs en helt spesiell oppbygning, altså en arkitektur av nevrale nettverk for å få det til.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 15_l_re_maskiner_se_40.wav\n",
      "Original Text: Et nevralt nettverk kan ha en hvilken som helst arkitektur, og vi som forsker på kunstig intelligens kan sette sammen noder i lag av hjertens lyst.\n",
      "Normalized Text: Et nevralt nettverk kan ha en hvilken som helst arkitektur, og vi som forsker på kunstig intelligens kan sette sammen noder i lag av hjertens lyst.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 15_l_re_maskiner_se_41.wav\n",
      "Original Text: Spørsmålet er bare om nettverket vi designer er i stand til å lære seg det vi vil at det skal lære seg, for eksempel hva som er på bilder.\n",
      "Normalized Text: Spørsmålet er bare om nettverket vi designer er i stand til å lære seg det vi vil at det skal lære seg, for eksempel hva som er på bilder.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 15_l_re_maskiner_se_42.wav\n",
      "Original Text: Når du tar et bilde med mobiltelefonen har bildet et par megapiksler, og mega står for millioner.\n",
      "Normalized Text: Når du tar et bilde med mobiltelefonen har bildet et par megapiksler, og mega står for millioner.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 15_l_re_maskiner_se_43.wav\n",
      "Original Text: Det betyr at bildet består av et par millioner ruter som alle har en farge.\n",
      "Normalized Text: Det betyr at bildet består av et par millioner ruter som alle har en farge.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 15_l_re_maskiner_se_44.wav\n",
      "Original Text: Fargen beskrives av tre verdier, for eksempel 255,0,0 som betyr rød, 255,255,0 som betyr gul, eller 255,204,204 som betyr lyserosa.\n",
      "Normalized Text: Fargen beskrives av tre verdier, for eksempel to hundre og femti fem, null, null som betyr rød, to hundre og femti fem, to hundre og femti fem, null som betyr gul, eller to hundre og femti fem, to hundre og fire, to hundre og fire som betyr lyserosa.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 15_l_re_maskiner_se_45.wav\n",
      "Original Text: Disse tre tallene forteller telefonen eller maskinen som skal vise bildet hvor mye rød, grønn eller blå farge som skal blandes sammen for at denne pikselen skal spille på lag med de andre millionene av pikseler for å vise nøyaktig det bildet du knipset.\n",
      "Normalized Text: Disse tre tallene forteller telefonen eller maskinen som skal vise bildet hvor mye rød, grønn eller blå farge som skal blandes sammen for at denne pikselen skal spille på lag med de andre millionene av pikseler for å vise nøyaktig det bildet du knipset.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 15_l_re_maskiner_se_46.wav\n",
      "Original Text: Det høres kanskje ut som et mareritt å måtte forholde seg til millioner av lister med tre tall, men det er slik maskiner ser bilder.\n",
      "Normalized Text: Det høres kanskje ut som et mareritt å måtte forholde seg til millioner av lister med tre tall, men det er slik maskiner ser bilder.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 15_l_re_maskiner_se_48.wav\n",
      "Original Text: Og vi kan takke hjernen vår for at vi gjør det dagen lang uten at vi engang behøver å tenke over det.\n",
      "Normalized Text: Og vi kan takke hjernen vår for at vi gjør det dagen lang uten at vi engang behøver å tenke over det.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 15_l_re_maskiner_se_49.wav\n",
      "Original Text: Men hvordan skal datamaskiner klare å gå fra millioner av tall til å se denne helheten?\n",
      "Normalized Text: Men hvordan skal datamaskiner klare å gå fra millioner av tall til å se denne helheten?\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 15_l_re_maskiner_se_50.wav\n",
      "Original Text: De første hintene om hvordan datamaskiner kan gjøre dette, er å finne i det som skulle bli en av de mest innflytelsesrike studiene for maskinell bildeforståelse.\n",
      "Normalized Text: De første hintene om hvordan datamaskiner kan gjøre dette, er å finne i det som skulle bli en av de mest innflytelsesrike studiene for maskinell bildeforståelse.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 15_l_re_maskiner_se_51.wav\n",
      "Original Text: Den ble gjort i 1959 og het Receptive Fields of Single Neurons in the Cat's Striate Cortex, altså en studie om katter.\n",
      "Normalized Text: Den ble gjort i nitten femti-ni og het Receptive Fields of Single Neurons in the Cat's Striate Cortex, altså en studie om katter.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 15_l_re_maskiner_se_52.wav\n",
      "Original Text: Studien så på egenskapene til nervecellene i synsparken som ligger bakerst i hjernen, både hos katter og hos mennesker.\n",
      "Normalized Text: Studien så på egenskapene til nervecellene i synsparken som ligger bakerst i hjernen, både hos katter og hos mennesker.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 15_l_re_maskiner_se_53.wav\n",
      "Original Text: Forskerne bak studien, David Hubel og Torsten Wiesel, gjorde temmelig intrikate eksperimenter,\n",
      "Normalized Text: Forskerne bak studien, David Hubel og Torsten Wiesel, gjorde temmelig intrikate eksperimenter,\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 15_l_re_maskiner_se_54.wav\n",
      "Original Text: De plasserte elektroder i synsparken til katten, og brukte elektrodene til å registrere aktiviteten i nevronene som lå i dette hjerneområdet når de viste katten ulike bilder.\n",
      "Normalized Text: De plasserte elektroder i synsparken til katten, og brukte elektrodene til å registrere aktiviteten i nevronene som lå i dette hjerneområdet når de viste katten ulike bilder.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 15_l_re_maskiner_se_55.wav\n",
      "Original Text: Problemet var at nervecellene i synsparken nektet å reagere, uansett hvilke bilder de viste katten.\n",
      "Normalized Text: Problemet var at nervecellene i synsparken nektet å reagere, uansett hvilke bilder de viste katten.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 15_l_re_maskiner_se_56.wav\n",
      "Original Text: Som så ofte ellers i vitenskapen skulle det litt flaks og tilfeldigheter til for å gjøre gjennombruddet.\n",
      "Normalized Text: Som så ofte ellers i vitenskapen skulle det litt flaks og tilfeldigheter til for å gjøre gjennombruddet.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 15_l_re_maskiner_se_57.wav\n",
      "Original Text: Helt utilsiktet merket forskerne etter flere måneder med eksperimenter at et nevron fyrte av da forskerne byttet mellom to bilder på skjermen.\n",
      "Normalized Text: Helt utilsiktet merket forskerne etter flere måneder med eksperimenter at et nevron fyrte av da forskerne byttet mellom to bilder på skjermen.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 15_l_re_maskiner_se_58.wav\n",
      "Original Text: Etter at den umiddelbare forvirringen hadde lagt seg, forstod forskerne at nevronene hadde reagert på en rett linje som ble dannet av skyggen til det nye bildet.\n",
      "Normalized Text: Etter at den umiddelbare forvirringen hadde lagt seg, forstod forskerne at nevronene hadde reagert på en rett linje som ble dannet av skyggen til det nye bildet.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 15_l_re_maskiner_se_59.wav\n",
      "Original Text: Etter ytterligere eksperimenter kunne forskerne konkludere med at det finnes både enkle og mer komplekse nerveceller i synsparken.\n",
      "Normalized Text: Etter ytterligere eksperimenter kunne forskerne konkludere med at det finnes både enkle og mer komplekse nerveceller i synsparken.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 15_l_re_maskiner_se_60.wav\n",
      "Original Text: og at opplevelsen av synsinntrykkene vi mottar alltid starter med enkle strukturer som kanter og streker.\n",
      "Normalized Text: og at opplevelsen av synsinntrykkene vi mottar alltid starter med enkle strukturer som kanter og streker.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 15_l_re_maskiner_se_61.wav\n",
      "Original Text: Dette er nemlig i den rekkefølgen hjernen til både oss mennesker og mange dyr behandler synsinformasjon som treffer øyet.\n",
      "Normalized Text: Dette er nemlig i den rekkefølgen hjernen til både oss mennesker og mange dyr behandler synsinformasjon som treffer øyet.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 15_l_re_maskiner_se_64.wav\n",
      "Original Text: før vi til slutt behandler de komplekse delene av det vi ser på, og forstår hva det er.\n",
      "Normalized Text: før vi til slutt behandler de komplekse delene av det vi ser på, og forstår hva det er.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 15_l_re_maskiner_se_65.wav\n",
      "Original Text: Denne prosessen skjer altså i en bestemt rekkefølge, og dessuten i ulike deler av hjernen.\n",
      "Normalized Text: Denne prosessen skjer altså i en bestemt rekkefølge, og dessuten i ulike deler av hjernen.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 15_l_re_maskiner_se_66.wav\n",
      "Original Text: For at nevrale nettverk skal kunne lære seg å forstå bilder, er løsningen en arkitektur der systemet først finner enkle strukturer, for så å identifisere mer kompliserte mønstre.\n",
      "Normalized Text: For at nevrale nettverk skal kunne lære seg å forstå bilder, er løsningen en arkitektur der systemet først finner enkle strukturer, for så å identifisere mer kompliserte mønstre.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n",
      "Audio Path: 15_l_re_maskiner_se_67.wav\n",
      "Original Text: Den første gangen et slikt nevralt nettverk ble utviklet var i 1979 av den japanske informatikeren Kunihiko Fukushima.\n",
      "Normalized Text: Den første gangen et slikt nevralt nettverk ble utviklet var i nittenogsytti-ni av den japanske informatikeren Kunihiko Fukushima.\n",
      "Speaker Number: 6\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from pyparsing import Word, nums, Combine, Suppress, Optional, alphas, alphanums, Literal\n",
    "\n",
    "# Define the pyparsing grammar for numbers, dates, and percentages\n",
    "def create_parser():\n",
    "    # Basic number (integer and decimal)\n",
    "    number = Word(nums)\n",
    "    decimal_number = Combine(Word(nums) + \".\" + Word(nums))\n",
    "    \n",
    "    # Date patterns (e.g., 23/10/2024, 2. juni)\n",
    "    day = Word(nums, max=2)\n",
    "    month = Word(alphas, max=10) | Word(nums, max=2)\n",
    "    year = Word(nums, min=4, max=4)\n",
    "    date = Combine(day + Suppress(\"/\") + month + Suppress(\"/\") + year) | Combine(day + Suppress(\".\") + month)\n",
    "    \n",
    "    # Number with units (e.g., kg, kr)\n",
    "    number_with_unit = Combine(number + Optional(Literal(\"kg\") | Literal(\"kr\") | Literal(\"%\")))\n",
    "    \n",
    "    # Full parser: detect any of the patterns\n",
    "    parser = number | decimal_number | date | number_with_unit\n",
    "    return parser\n",
    "\n",
    "# Check if the text contains any patterns that require normalization\n",
    "def needs_normalization(text, parser):\n",
    "    # Try parsing the text using the defined parser\n",
    "    try:\n",
    "        matches = parser.searchString(text)\n",
    "        return len(matches) > 0\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def get_all_text_in_dict(input_file_path, output_file_path, client, model=\"gpt-4o-mini\", k=10000):\n",
    "    \"\"\"\n",
    "    Reads the input file, normalizes the second column (text) using GPT-4 mini if needed, and saves the results to the output file.\n",
    "    \n",
    "    Params:\n",
    "    - input_file_path: Path to the input file containing audio_path, text, and speaker_nr.\n",
    "    - output_file_path: Path to the output file where normalized text will be saved.\n",
    "    - client: OpenAI client instance for making API requests.\n",
    "    - model: The model to use for normalization (default: 'gpt-4o-mini').\n",
    "    - k: Maximum number of lines to process.\n",
    "    \n",
    "    Returns:\n",
    "    - processed_texts: A dictionary of the processed texts where keys are audio_path, and values are dictionaries with 'original_text', 'normalized_text', and 'speaker_nr'.\n",
    "    \"\"\"\n",
    "    processed_texts = {}\n",
    "    \n",
    "    # Initialize the parser\n",
    "    parser = create_parser()\n",
    "    \n",
    "    # Open the input and output files\n",
    "    with open(input_file_path, 'r', encoding='utf-8') as infile, open(output_file_path, 'w', encoding='utf-8') as outfile:\n",
    "        \n",
    "        for i, line in enumerate(infile):\n",
    "            # Split the line into audio_path, text, and speaker_nr\n",
    "            columns = line.split('|')\n",
    "            if len(columns) < 3:\n",
    "                continue  # Skip lines that do not have all columns\n",
    "            \n",
    "            audio_path = columns[0].strip()\n",
    "            original_text = columns[1].strip()\n",
    "            speaker_nr = columns[2].strip()\n",
    "            \n",
    "            # Check if the text needs normalization using pyparsing\n",
    "            if needs_normalization(original_text, parser):\n",
    "                # If normalization is needed, call the OpenAI API\n",
    "                response = client.chat.completions.create(\n",
    "                    model=model,\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": \"I want you to act as a text-normalizer for Norwegian. I will provide dates, times, numbers, or other abbreviations, and you will convert them into their full, orthographically correct Norwegian forms. Please convert all numbers to their written form and do not include any explanations or additional information in your responses.\"},\n",
    "                        {\"role\": \"user\", \"content\": original_text}\n",
    "                    ],\n",
    "                    max_tokens=2000,\n",
    "                    temperature=0.0\n",
    "                )\n",
    "                \n",
    "                # Extract the normalized text\n",
    "                normalized_text = response.choices[0].message.content.strip()\n",
    "            else:\n",
    "                # If no normalization is needed, keep the original text\n",
    "                normalized_text = original_text\n",
    "            \n",
    "            # Write the normalized (or original) text back to the output file and save to dictionary\n",
    "            outfile.write(f\"{audio_path}|{normalized_text}|{speaker_nr}\\n\")\n",
    "            \n",
    "            # Store the processed result in the dictionary\n",
    "            processed_texts[audio_path] = {\n",
    "                'original_text': original_text,\n",
    "                'normalized_text': normalized_text,\n",
    "                'speaker_nr': speaker_nr\n",
    "            }\n",
    "            \n",
    "            # Stop after processing `k` lines (if required)\n",
    "            if (i + 1) >= k:\n",
    "                break\n",
    "\n",
    "    return processed_texts\n",
    "\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "# Example usage\n",
    "input_file_path = 'outputbooks.txt'\n",
    "output_file_path = 'normalized_output.txt'\n",
    "processed_data = get_all_text_in_dict(input_file_path, output_file_path, client)\n",
    "\n",
    "# Print the returned data for verification\n",
    "# Print only the first 100 items for verification\n",
    "for idx, (audio_path, data) in enumerate(processed_data.items()):\n",
    "    if idx >= 100:\n",
    "        break\n",
    "    print(f\"Audio Path: {audio_path}\")\n",
    "    print(f\"Original Text: {data['original_text']}\")\n",
    "    print(f\"Normalized Text: {data['normalized_text']}\")\n",
    "    print(f\"Speaker Number: {data['speaker_nr']}\")\n",
    "    print(\"-\" * 50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53644b8b-e87f-4147-8c06-a8ea62fd6041",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
